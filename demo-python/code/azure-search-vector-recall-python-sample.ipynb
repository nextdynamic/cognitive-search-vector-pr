{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Cognitive Search Vector Search Recall Measurement Code Sample\n",
    "\n",
    "This code demonstrates how to measure recall for vectors in Azure Cognitive Search using Azure Python SDK\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "To run the code, install the following packages. Please use the latest pre-release version `pip install azure-search-documents --pre`.\n",
    "\n",
    "# https://learn.microsoft.com/en-gb/azure/search/vector-search-overview\n",
    "# https://learn.microsoft.com/en-us/python/api/overview/azure/?view=azure-python\n",
    "# https://learn.microsoft.com/en-us/python/api/azure-search-documents/?view=azure-python\n",
    "# https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/search/azure-search-documents\n",
    "# https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/search/azure-search-documents/samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://pypi.org/project/azure-search-documents/11.4.0b8/\n",
    "##! pip install azure-search-documents --pre\n",
    "# ! pip install azure-search-documents==11.4.0b8\n",
    "# ! pip install python-dotenv\n",
    "# ! pip install numpy\n",
    "# ! pip install azure.storage.blob\n",
    "# ! pip install scipy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries  \n",
    "import os  \n",
    "import json\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient  \n",
    "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient\n",
    "from azure.search.documents.models import Vector  \n",
    "from azure.search.documents.indexes.models import (  \n",
    "    SearchIndex,  \n",
    "    SearchField,  \n",
    "    SearchFieldDataType,  \n",
    "    SimpleField,\n",
    "    SearchableField,  \n",
    "    SearchIndex,  \n",
    "    SearchIndexerDataContainer,  \n",
    "    SearchIndexer,  \n",
    "    SearchIndexerDataSourceConnection,  \n",
    "    IndexingParameters,\n",
    "    SemanticConfiguration,  \n",
    "    PrioritizedFields,  \n",
    "    SemanticField,  \n",
    "    SearchField,  \n",
    "    SemanticSettings,  \n",
    "    VectorSearch,\n",
    "    HnswVectorSearchAlgorithmConfiguration,  \n",
    ")  \n",
    "from azure.storage.blob import BlobServiceClient \n",
    "from scipy.spatial.distance import cdist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://cog-search-nonprod-eastus-001.search.windows.net\n",
      "cog-search-nonprod-eastus-001\n",
      "cogsrch-vector-index\n",
      "K43abh5MhRQvlEErXNJX5zpu9e4btDtOHJ3qOAPigDAzSeC14WZRY\n",
      "DefaultEndpointsProtocol=https;AccountName=stcogsvceastus001;AccountKey=bPR606bf28x4VK0mqbTnbOikOJFd5FjDdcU+kGEqSIfF+UOl/CmcIvtcCU/OzEQ7Acyr6hTt+q0Q+AStmMlyOg==;EndpointSuffix=core.windows.net\n",
      "vector\n",
      "indexblobfolder\n",
      "YOUR-QUERYING-DATASET-BLOB-NAME\n",
      "K43abh5MhRQvlEErXNJX5zpu9e4btDtOHJ3qOAPigDAzSeC14WZRY\n",
      "cogsrch-vector-index\n"
     ]
    }
   ],
   "source": [
    "# Configure environment variables  \n",
    " \n",
    "\n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "print(service_endpoint)\n",
    "\n",
    "service_name = os.getenv(\"AZURE_SERVICE_NAME\")\n",
    "print(service_name)\n",
    "\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")  \n",
    "print(index_name)\n",
    "\n",
    "key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")  \n",
    "print(key)\n",
    "\n",
    "blob_connection_string = os.getenv(\"BLOB_CONNECTION_STRING\")  \n",
    "print(blob_connection_string)\n",
    "\n",
    "container_name = os.getenv(\"BLOB_CONTAINER_NAME\")\n",
    "print(container_name)\n",
    "\n",
    "index_blob_folder = os.getenv(\"INDEX_BLOB_FOLDER\")\n",
    "print(index_blob_folder)\n",
    "\n",
    "query_blob_name = os.getenv(\"QUERY_BLOB_NAME\")\n",
    "print(query_blob_name)\n",
    "\n",
    "admin_key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "print(admin_key)\n",
    "\n",
    "index_name=os.getenv(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "print(index_name)\n",
    "\n",
    "#credential = AzureKeyCredential(key)\n",
    "search_field = \"contentVector\"\n",
    "\n",
    "# Supports cosine and euclidean\n",
    "metric = \"cosine\"\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the seach client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the service endpoint and API key from the environment\n",
    "\n",
    "# Create an SDK client\n",
    "endpoint = f\"https://{service_name}.search.windows.net/\"\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint,\n",
    "                      index_name=index_name,\n",
    "                      credential=AzureKeyCredential(admin_key))\n",
    "\n",
    "search_client = SearchClient(endpoint=endpoint,\n",
    "                      index_name=index_name,\n",
    "                      credential=AzureKeyCredential(admin_key))\n",
    "\n",
    "search_indexer_client = SearchIndexerClient(endpoint, AzureKeyCredential(admin_key))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your search index\n",
    "\n",
    "Create your search index schema and vector search configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dimensions is not a known attribute of class <class 'azure.search.documents.indexes.models._index.SearchField'> and will be ignored\n",
      "dimensions is not a known attribute of class <class 'azure.search.documents.indexes.models._index.SearchField'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation returned an invalid status 'Forbidden'\n"
     ]
    }
   ],
   "source": [
    "# Create a search index\n",
    "# https://learn.microsoft.com/en-us/python/api/azure-search-documents/azure.search.documents.indexes.models.searchfield?view=azure-python\n",
    "\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "    SearchableField(name=\"title\", type=SearchFieldDataType.String, searchable=True, retrievable=True),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String, searchable=True, retrievable=True),\n",
    "    SearchField(name=\"titleVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), searchable=True, dimensions=1536, vector_search_configuration=\"my-vector-config\"),\n",
    "    SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), searchable=True, dimensions=1536, vector_search_configuration=\"my-vector-config\"),\n",
    "]\n",
    "\n",
    "vector_search = VectorSearch(\n",
    "    algorithm_configurations=[\n",
    "        HnswVectorSearchAlgorithmConfiguration(\n",
    "            name=\"my-vector-config\",\n",
    "            kind=\"hnsw\",\n",
    "            parameters={\n",
    "                \"m\": 4,\n",
    "                \"efConstruction\": 400,\n",
    "                \"efSearch\": 1000,\n",
    "                \"metric\": metric\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"vector-semantic-config\",\n",
    "    prioritized_fields=PrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        prioritized_content_fields=[SemanticField(field_name=\"content\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_settings = SemanticSettings(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields,\n",
    "                    vector_search=vector_search, semantic_settings=semantic_settings)\n",
    "\n",
    "\n",
    "try:\n",
    "    result = index_client.create_or_update_index(index)\n",
    "    print(f' {result.name} created')\n",
    "\n",
    "except Exception as ex:\n",
    "    print (ex)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Blob Storage\n",
    "blob_service_client = BlobServiceClient.from_connection_string(blob_connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "blob_url = container_client.get_blob_client(query_blob_name).url\n",
    "print(f\"URL of the blob: {blob_url}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect your Blob Storage to a data source in Cognitive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data source \n",
    "ds_client = SearchIndexerClient(service_endpoint, AzureKeyCredential(key))\n",
    "container = SearchIndexerDataContainer(name=container_name, query=index_blob_folder)\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=f\"{index_name}-blob\",\n",
    "    type=\"azureblob\",\n",
    "    connection_string=blob_connection_string,\n",
    "    container=container\n",
    ")\n",
    "data_source = ds_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "print(f\"Data source '{data_source.name}' created or updated\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an indexer\n",
    "\n",
    "Create or update an indexer to populate the search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an indexer  \n",
    "indexer_name = f\"{index_name}-indexer\"  \n",
    "parameters = IndexingParameters(configuration={\"parsingMode\": \"jsonArray\"})\n",
    "\n",
    "indexer = SearchIndexer(  \n",
    "    name=indexer_name,  \n",
    "    description=\"Indexer to index SciFact dataset\",  \n",
    "    target_index_name=index_name,  \n",
    "    data_source_name=data_source.name,\n",
    "    parameters=parameters\n",
    ")  \n",
    "  \n",
    "indexer_client = SearchIndexerClient(service_endpoint, AzureKeyCredential(key))  \n",
    "indexer_result = indexer_client.create_or_update_indexer(indexer)  \n",
    "  \n",
    "# Run the indexer  \n",
    "indexer_client.run_indexer(indexer_name)  \n",
    "print(f' {indexer_name} created')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing indexing dataset from container\n",
    "Fetch train_vectors, id and map ids to it's list indices for calculating ground truth values and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data_from_container(container_client, folder_name):\n",
    "    blobs = container_client.list_blobs(name_starts_with=folder_name)\n",
    "\n",
    "    json_array = []\n",
    "    for blob in blobs:\n",
    "        blob_client = container_client.get_blob_client(blob)\n",
    "        blob_data = blob_client.download_blob().readall()\n",
    "        json_array.append(blob_data.decode('utf-8'))\n",
    "\n",
    "    return json_array\n",
    "\n",
    "# Load train data\n",
    "data = load_train_data_from_container(container_client, index_blob_folder)\n",
    "\n",
    "# Fetch vectors and id from train dataset and map ids to indices for ground truth and recall calculation\n",
    "train_data = []\n",
    "for d in data:\n",
    "    train_data.extend(json.loads(d))\n",
    "print(f'Total no. of documents: {len(train_data)}')\n",
    "\n",
    "train_vectors, train_ids = zip(*[(h[\"contentVector\"], h[\"id\"]) for h in train_data])\n",
    "\n",
    "train_id_to_indices = {}\n",
    "for i in range(len(train_ids)):\n",
    "    train_id_to_indices[f'{train_ids[i]}'] = i"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load querying dataset from container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch query vectors from query dataset\n",
    "test_data_contents = blob_service_client.get_blob_client(container=container_name, blob=query_blob_name).download_blob().readall()\n",
    "test_data = json.loads(test_data_contents)\n",
    "\n",
    "query_vectors = [h[search_field] for h in test_data]\n",
    "print(f'No. of query vectors: {len(query_vectors)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Ground Truth Values\n",
    "\n",
    "We calculate ground truth values for each query vector by finding the top 'k' neighbors in train_data based on their distance to the query vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metric distances between train and test vectors\n",
    "distances = cdist(query_vectors, train_vectors, metric=metric)\n",
    "\n",
    "# Get the indices of k closest neighbors for each test vector\n",
    "indices = np.argsort(distances, axis=1)[:, :k]\n",
    "\n",
    "# Create a 2D array of k closest neighbors for each test vector\n",
    "neighbors = np.take(train_ids, indices, axis=0)\n",
    "print(f'Top {k} neighbors id for 1st query vector: {neighbors[0]}')\n",
    "\n",
    "# Create a 2D array of the distances of k closest neighbors for each test vector\n",
    "distances = distances[np.arange(len(query_vectors))[:, np.newaxis], indices]\n",
    "print(f'Distance of top {k} neighbors for 1st query vector: {distances[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Vector search\n",
    "\n",
    "Perform vector search for all the query vectors and store the response ids for recall measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform vector search and fetch the ids from response for each query vector  \n",
    "search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))  \n",
    "results = []  \n",
    "for query in test_data:  \n",
    "    vector = Vector(value=query[\"contentVector\"], k=k, fields=search_field)  \n",
    "    result = search_client.search(  \n",
    "        search_text=None,  \n",
    "        vectors=[vector],  \n",
    "        select=[\"id\"]  \n",
    "    )  \n",
    "    result_ids = [int(h['id']) for h in result]  \n",
    "    results.append(result_ids)  \n",
    "  \n",
    "print(f'Result ids for 1st query vector: {results[0]}')  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure distance between query vector and its response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_query_response_distance(vector1, vector2, metric):\n",
    "    return float(cdist(vector1, vector2, metric=metric)[0])\n",
    "\n",
    "query_response_distances = np.empty((len(results), k))\n",
    "for i in range(len(results)):\n",
    "    for j in range(k):\n",
    "        if j >= len(results[i]):\n",
    "            query_response_distances[i][j] = float('inf')\n",
    "            continue\n",
    "        query_response_distances[i][j] = calculate_query_response_distance([query_vectors[i]], [train_vectors[train_id_to_indices[f\"{results[i][j]}\"]]], metric)\n",
    "\n",
    "print(f'Query Response distance for 1st query vector: {query_response_distances[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure Recall\n",
    "\n",
    "Calculate a threshold value for each query which would be approximately the distance of the k'th vector for the respective query vector in the ground truth value. \n",
    "We count all those response vectors as relevant result which are below these threshold values and get the recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_threshold(data, count, epsilon):\n",
    "    return data[count - 1] + epsilon\n",
    "\n",
    "recall = np.zeros(len(results))\n",
    "\n",
    "for i in range(len(results)):\n",
    "    threshold = calculate_threshold(distances[i], k, 1e-3)\n",
    "    count = 0\n",
    "    for d in query_response_distances[i]:\n",
    "        if d <= threshold:\n",
    "            count += 1\n",
    "    recall[i] = count\n",
    "\n",
    "overall_recall = np.mean(recall) / float(k)\n",
    "print(f'Recall: {overall_recall}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
