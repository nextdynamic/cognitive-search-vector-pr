{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Cognitive Search Vector Search Code Sample with Azure OpenAI\n",
    "This code demonstrates how to use Azure Cognitive Search with OpenAI and Azure Python SDK\n",
    "## Prerequisites\n",
    "To run the code, install the following packages. Please use the latest pre-release version `pip install azure-search-documents --pre`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##! pip install azure-search-documents --pre\n",
    "##! pip install openai\n",
    "##! pip install python-dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<azure.core.credentials.AzureKeyCredential object at 0x000002974CF15B50>\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries  \n",
    "import os  \n",
    "import json  \n",
    "import openai  \n",
    "import azure.core.exceptions\n",
    "from dotenv import load_dotenv  \n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient  \n",
    "from azure.search.documents.indexes import SearchIndexClient  \n",
    "from azure.search.documents.models import Vector  \n",
    "from azure.search.documents.indexes.models import (  \n",
    "    SearchIndex,  \n",
    "    SearchField,  \n",
    "    SearchFieldDataType,  \n",
    "    SimpleField,  \n",
    "    SearchableField,  \n",
    "    SearchIndex,  \n",
    "    SemanticConfiguration,  \n",
    "    PrioritizedFields,  \n",
    "    SemanticField,  \n",
    "    SearchField,  \n",
    "    SemanticSettings,  \n",
    "    VectorSearch,  \n",
    "    HnswVectorSearchAlgorithmConfiguration,  \n",
    ")  \n",
    "  \n",
    "# Configure environment variables  \n",
    "load_dotenv()  \n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\") \n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\") \n",
    "admin_key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\") \n",
    "openai.api_type = \"azure\"  \n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")  \n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")  \n",
    "openai.api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")  \n",
    "\n",
    "credential = AzureKeyCredential(admin_key)\n",
    "\n",
    "#print(os.environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a search index\n",
    "index_client = SearchIndexClient(endpoint=service_endpoint, index_name=index_name, credential=credential)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings\n",
    "Read your data, generate OpenAI embeddings and export to a format to insert your Azure Cognitive Search index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Document Embeddings using OpenAI Ada 002\n",
    "\n",
    "# Read the text-sample.json\n",
    "with open('../data/text-sample.json', 'r', encoding='utf-8') as file:\n",
    "    input_data = json.load(file)\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "def generate_embeddings(text):\n",
    "    response = openai.Embedding.create(\n",
    "        input=text, engine=\"text-embedding-ada-002\")\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# Generate embeddings for title and content fields\n",
    "for item in input_data:\n",
    "    title = item['title']\n",
    "    content = item['content']\n",
    "    title_embeddings = generate_embeddings(title)\n",
    "    content_embeddings = generate_embeddings(content)\n",
    "    item['titleVector'] = title_embeddings\n",
    "    item['contentVector'] = content_embeddings\n",
    "\n",
    "# Output embeddings to docVectors.json file\n",
    "with open(\"../output/docVectors.json\", \"w\") as f:\n",
    "    json.dump(input_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(indexName: str):\n",
    "    # https://azuresdkdocs.blob.core.windows.net/$web/python/azure-search-documents/latest/azure.search.documents.indexes.html#subpackages\n",
    "\n",
    "    try:\n",
    "        result = index_client.get_index(indexName)\n",
    "        print(\"Get Index succeeded\")\n",
    "        return result\n",
    "    except azure.core.exceptions.HttpResponseError as he:\n",
    "        print (\"get_index --> HttpResponseError: \" + str(he))\n",
    "    except Exception as ex:\n",
    "        print (\"get_index --> Exception: \" + str(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the index if it exists\n",
    "def delete_index(indexName: str ):\n",
    "\n",
    "    try:\n",
    "\n",
    "        # check if index exists\n",
    "        if index_client.get_index(indexName) is not None:\n",
    "        \n",
    "            try:\n",
    "                result = index_client.delete_index(indexName)\n",
    "                print ('Index', index_name, 'Deleted')\n",
    "            except azure.core.exceptions.HttpResponseError as he:\n",
    "                print (\"delete_index --> HttpResponseError: \" + str(he))\n",
    "            except Exception as ex:\n",
    "                print (\"delete_index --> Exception: \" + str(ex))\n",
    "                \n",
    "    except azure.core.exceptions.HttpResponseError as he:\n",
    "        print (\"delete_index --> HttpResponseError: \" + str(he))\n",
    "    except Exception as ex:\n",
    "        print (\"delete_index --> Exception: \" + str(ex))   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your search index\n",
    "Create your search index schema and vector search configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete_index --> HttpResponseError: Operation returned an invalid status 'Forbidden'\n"
     ]
    },
    {
     "ename": "HttpResponseError",
     "evalue": "Operation returned an invalid status 'Forbidden'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39m# Create the search index with the semantic settings\u001b[39;00m\n\u001b[0;32m     41\u001b[0m index \u001b[39m=\u001b[39m SearchIndex(name\u001b[39m=\u001b[39mindex_name, fields\u001b[39m=\u001b[39mfields,vector_search\u001b[39m=\u001b[39mvector_search, semantic_settings\u001b[39m=\u001b[39msemantic_settings)\n\u001b[1;32m---> 43\u001b[0m result \u001b[39m=\u001b[39m index_client\u001b[39m.\u001b[39;49mcreate_index( index )\n\u001b[0;32m     45\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m created\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\tibrown\\GitHub\\cognitive-search-vector-pr\\.venv\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[0;32m     77\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[1;32mc:\\Users\\tibrown\\GitHub\\cognitive-search-vector-pr\\.venv\\Lib\\site-packages\\azure\\search\\documents\\indexes\\_search_index_client.py:211\u001b[0m, in \u001b[0;36mSearchIndexClient.create_index\u001b[1;34m(self, index, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_client_headers(kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m    210\u001b[0m patched_index \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39m_to_generated()  \u001b[39m# pylint:disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49mindexes\u001b[39m.\u001b[39;49mcreate(patched_index, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mreturn\u001b[39;00m SearchIndex\u001b[39m.\u001b[39m_from_generated(result)\n",
      "File \u001b[1;32mc:\\Users\\tibrown\\GitHub\\cognitive-search-vector-pr\\.venv\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[0;32m     77\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[1;32mc:\\Users\\tibrown\\GitHub\\cognitive-search-vector-pr\\.venv\\Lib\\site-packages\\azure\\search\\documents\\indexes\\_generated\\operations\\_indexes_operations.py:403\u001b[0m, in \u001b[0;36mIndexesOperations.create\u001b[1;34m(self, index, request_options, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m     map_error(status_code\u001b[39m=\u001b[39mresponse\u001b[39m.\u001b[39mstatus_code, response\u001b[39m=\u001b[39mresponse, error_map\u001b[39m=\u001b[39merror_map)\n\u001b[0;32m    402\u001b[0m     error \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deserialize\u001b[39m.\u001b[39mfailsafe_deserialize(_models\u001b[39m.\u001b[39mSearchError, pipeline_response)\n\u001b[1;32m--> 403\u001b[0m     \u001b[39mraise\u001b[39;00m HttpResponseError(response\u001b[39m=\u001b[39mresponse, model\u001b[39m=\u001b[39merror)\n\u001b[0;32m    405\u001b[0m deserialized \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deserialize(\u001b[39m\"\u001b[39m\u001b[39mSearchIndex\u001b[39m\u001b[39m\"\u001b[39m, pipeline_response)\n\u001b[0;32m    407\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m:\n",
      "\u001b[1;31mHttpResponseError\u001b[0m: Operation returned an invalid status 'Forbidden'"
     ]
    }
   ],
   "source": [
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchableField(name=\"title\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"category\", type=SearchFieldDataType.String,filterable=True),\n",
    "    SearchField(name=\"titleVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),searchable=True, vector_search_dimensions=1536, vector_search_configuration=\"my-vector-config\"),\n",
    "    SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), searchable=True, vector_search_dimensions=1536, vector_search_configuration=\"my-vector-config\"),\n",
    "]\n",
    "\n",
    "vector_search = VectorSearch(\n",
    "    algorithm_configurations=[\n",
    "        HnswVectorSearchAlgorithmConfiguration(\n",
    "            name=\"my-pr-vector-config\",\n",
    "            kind=\"hnsw\",\n",
    "            parameters={\n",
    "                \"m\": 4,\n",
    "                \"efConstruction\": 400,\n",
    "                \"efSearch\": 500,\n",
    "                \"metric\": \"cosine\"\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-pr-semantic-config\",\n",
    "    prioritized_fields=PrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        prioritized_keywords_fields=[SemanticField(field_name=\"category\")],\n",
    "        prioritized_content_fields=[SemanticField(field_name=\"content\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_settings = SemanticSettings(configurations=[semantic_config])\n",
    "\n",
    "# delete the index if it already exists\n",
    "delete_index( index_name )\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields,vector_search=vector_search, semantic_settings=semantic_settings)\n",
    "\n",
    "result = index_client.create_index( index )\n",
    "\n",
    "print(f' {result.name} created')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert text and embeddings into vector store\n",
    "Add texts and metadata from the JSON data to the vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload some documents to the index\n",
    "with open('../output/docVectors.json', 'r') as file:  \n",
    "    documents = json.load(file)  \n",
    "search_client = SearchClient(endpoint=service_endpoint, index_name=index_name, credential=credential)\n",
    "result = search_client.upload_documents(documents)  \n",
    "print(f\"Uploaded {len(documents)} documents\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Vector Search\n",
    "query = \"tools for software development\"  \n",
    "  \n",
    "search_client = SearchClient(service_endpoint, index_name, credential=credential)\n",
    "vector = Vector(value=generate_embeddings(query), k=3, fields=\"contentVector\")\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vectors= [vector],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['content']}\")  \n",
    "    print(f\"Category: {result['category']}\\n\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Vector Search multi-lingual (e.g 'tools for software development' in Dutch)  \n",
    "query = \"tools voor softwareontwikkeling\"  \n",
    "  \n",
    "search_client = SearchClient(service_endpoint, index_name, credential=credential)\n",
    "vector = Vector(value=generate_embeddings(query), k=3, fields=\"contentVector\")  \n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vectors=[vector],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['content']}\")  \n",
    "    print(f\"Category: {result['category']}\\n\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Cross-Field Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Field Vector Search\n",
    "query = \"tools for software development\"  \n",
    "  \n",
    "search_client = SearchClient(service_endpoint, index_name, credential=credential)  \n",
    "vector = Vector(value=generate_embeddings(query), k=3, fields=\"titleVector, contentVector\")  \n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vectors=[vector],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['content']}\")  \n",
    "    print(f\"Category: {result['category']}\\n\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Multi-Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Vector Search\n",
    "query = \"tools for software development\"  \n",
    "  \n",
    "search_client = SearchClient(service_endpoint, index_name, credential=credential)  \n",
    "vector1 = Vector(value=generate_embeddings(query), k=3, fields=\"titleVector\")  \n",
    "vector2 = Vector(value=generate_embeddings(query), k=3, fields=\"contentVector\")  \n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vectors=[vector1, vector2],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['content']}\")  \n",
    "    print(f\"Category: {result['category']}\\n\")  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Pure Vector Search with a filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Vector Search with Filter\n",
    "query = \"tools for software development\"  \n",
    "  \n",
    "search_client = SearchClient(service_endpoint, index_name, credential=credential)  \n",
    "vector = Vector(value=generate_embeddings(query), k=3, fields=\"contentVector\")  \n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vectors=[vector],\n",
    "    filter=\"category eq 'Developer Tools'\",\n",
    "    select=[\"title\", \"content\", \"category\"]\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['content']}\")  \n",
    "    print(f\"Category: {result['category']}\\n\")  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Search\n",
    "query = \"scalable storage solution\"  \n",
    "  \n",
    "search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))  \n",
    "vector = Vector(value=generate_embeddings(query), k=3, fields=\"contentVector\")  \n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vectors=[vector],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    "    top=3\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['content']}\")  \n",
    "    print(f\"Category: {result['category']}\\n\")  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Semantic Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Hybrid Search\n",
    "query = \"what is azure sarch?\"\n",
    "\n",
    "search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))\n",
    "vector = Vector(value=generate_embeddings(query), k=3, fields=\"contentVector\")  \n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vectors=[vector],\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    "    query_type=\"semantic\", query_language=\"en-us\", semantic_configuration_name='my-semantic-config', query_caption=\"extractive\", query_answer=\"extractive\",\n",
    "    top=3\n",
    ")\n",
    "\n",
    "semantic_answers = results.get_answers()\n",
    "for answer in semantic_answers:\n",
    "    if answer.highlights:\n",
    "        print(f\"Semantic Answer: {answer.highlights}\")\n",
    "    else:\n",
    "        print(f\"Semantic Answer: {answer.text}\")\n",
    "    print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "    print(f\"Category: {result['category']}\")\n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
